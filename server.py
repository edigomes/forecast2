from flask import Flask, request, jsonify
#from flask_cors import CORS
import pandas as pd
import logging
import json
import traceback
from modelo import ModeloAjustado
from feriados_brasil import FeriadosBrasil
from mrp import MRPOptimizer, OptimizationParams

app = Flask(__name__)

# Configurar CORS para permitir requests de qualquer URL
#CORS(app, resources={
#    r"/*": {
#        "origins": "*",  # Permite qualquer origem
#        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],  # M√©todos permitidos
#        "allow_headers": ["Content-Type", "Accept", "Authorization", "X-Requested-With"]  # Headers permitidos
#    }
#})

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json(force=True) or {}
    
    # Log COMPLETO dos dados de entrada
    logger.info("="*80)
    logger.info("DADOS DE ENTRADA COMPLETOS:")
    logger.info("-"*80)
    logger.info(f"granularidade: {data.get('granularidade', 'M')}")
    logger.info(f"periodos: {data.get('periodos', 0)}")
    logger.info(f"data_inicio: {data.get('data_inicio', '')}")
    logger.info(f"agrupamento_trimestral: {data.get('agrupamento_trimestral', False)}")
    logger.info(f"agrupamento_semestral: {data.get('agrupamento_semestral', False)}")
    logger.info(f"seasonal_smooth (se houver): {data.get('seasonal_smooth', 'n√£o informado')}")
    logger.info(f"seasonality_mode (se houver): {data.get('seasonality_mode', 'n√£o informado')}")
    logger.info(f"confidence_level (se houver): {data.get('confidence_level', 'n√£o informado')}")
    logger.info(f"confidence_factor (se houver): {data.get('confidence_factor', 'n√£o informado')}")
    logger.info(f"growth_factor (se houver): {data.get('growth_factor', 'n√£o informado')}")
    logger.info(f"month_adjustments (se houver): {data.get('month_adjustments', 'n√£o informado')}")
    logger.info(f"day_of_week_adjustments (se houver): {data.get('day_of_week_adjustments', 'n√£o informado')}")
    logger.info(f"feriados_enabled (se houver): {data.get('feriados_enabled', 'n√£o informado')}")
    logger.info(f"feriados_adjustments (se houver): {data.get('feriados_adjustments', 'n√£o informado')}")
    logger.info(f"anos_feriados (se houver): {data.get('anos_feriados', 'n√£o informado')}")
    logger.info(f"include_explanation (se houver): {data.get('include_explanation', 'n√£o informado')}")
    logger.info(f"explanation_level (se houver): {data.get('explanation_level', 'n√£o informado')}")
    logger.info(f"explanation_language (se houver): {data.get('explanation_language', 'n√£o informado')}")
    
    # Log COMPLETO dos dados de vendas
    sales_data = data.get("sales_data", [])
    if sales_data:
        logger.info(f"Quantidade de registros: {len(sales_data)}")
        logger.info("DADOS COMPLETOS DE VENDAS:")
        
        # Salvar dados completos em um arquivo JSON
        with open('dados_entrada_completos.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        logger.info(f"Dados completos salvos em 'dados_entrada_completos.json'")
        
        # Exibir dados completos nos logs
        logger.info(f"\nTODOS OS REGISTROS DE VENDAS:\n{json.dumps(sales_data, indent=2)}")
        
        # An√°lise dos dados
        if sales_data and isinstance(sales_data, list):
            df = pd.DataFrame(sales_data)
            if "item_id" in df.columns:
                unique_items = df["item_id"].unique().tolist()
                logger.info(f"item_ids √∫nicos ({len(unique_items)}): {unique_items}")
                
                # Estat√≠sticas detalhadas por item_id
                for item in unique_items:
                    item_df = df[df['item_id'] == item]
                    logger.info(f"\nEstat√≠sticas para item_id {item}:")
                    logger.info(f"  N√∫mero de registros: {len(item_df)}")
                    if 'timestamp' in item_df.columns:
                        dates = pd.to_datetime(item_df['timestamp'])
                        logger.info(f"  Per√≠odo: {min(dates)} a {max(dates)}")
                        logger.info(f"  Intervalo: {(max(dates) - min(dates)).days} dias")
                    if 'demand' in item_df.columns:
                        try:
                            demands = pd.to_numeric(item_df['demand'], errors='coerce')
                            logger.info(f"  Demanda m√≠nima: {demands.min()}")
                            logger.info(f"  Demanda m√°xima: {demands.max()}")
                            logger.info(f"  Demanda m√©dia: {demands.mean():.2f}")
                            logger.info(f"  Demanda total: {demands.sum():.2f}")
                        except Exception as e:
                            logger.error(f"Erro ao calcular estat√≠sticas: {e}")
    
    logger.info("-"*80)

    # Valida√ß√µes
    gran = data.get("granularidade", "M").upper()
    if gran not in ["M", "S", "D"]:
        return jsonify({"error":"'granularidade' deve ser 'M', 'S' ou 'D'."}), 400
    
    # Verificar se √© agrupamento trimestral ou semestral
    agrupamento_trimestral = data.get("agrupamento_trimestral", False)
    agrupamento_semestral = data.get("agrupamento_semestral", False)
    
    # Validar que n√£o sejam solicitados ambos ao mesmo tempo
    if agrupamento_trimestral and agrupamento_semestral:
        return jsonify({"error": "N√£o √© poss√≠vel usar agrupamento trimestral e semestral simultaneamente."}), 400
    
    # Para agrupamento trimestral ou semestral, for√ßar granularidade mensal
    if (agrupamento_trimestral or agrupamento_semestral) and gran != "M":
        tipo_agrupamento = "trimestral" if agrupamento_trimestral else "semestral"
        logger.info(f"Agrupamento {tipo_agrupamento} solicitado - for√ßando granularidade mensal")
        gran = "M"

    try:
        periods = int(data.get("periodos", 0))
    except:
        return jsonify({"error":"'periodos' deve ser inteiro."}), 400
    if periods < 1:
        return jsonify({"error":"'periodos' deve ser >= 1."}), 400

    try:
        start_date = pd.to_datetime(data.get("data_inicio",""), format="%Y-%m-%d")
    except:
        return jsonify({"error":"'data_inicio' inv√°lido. Use YYYY-MM-DD."}), 400

    if not isinstance(sales_data, list) or not sales_data:
        return jsonify({"error":"'sales_data' deve ser lista n√£o vazia."}), 400

    # Verifica se os dados t√™m as colunas necess√°rias
    df = pd.DataFrame(sales_data)
    if not {"item_id","timestamp","demand"}.issubset(df.columns):
        return jsonify({"error":"Cada registro precisa ter 'item_id','timestamp','demand'."}), 400

    try:
        # Prepara os dados para o modelo
        items_data = {}
        for item_id, grp in df.groupby("item_id"):
            items_data[int(item_id)] = {
                "timestamps": grp["timestamp"].tolist(),
                "demands": pd.to_numeric(grp["demand"], errors="coerce").tolist()
            }
        
        # Configura√ß√µes do modelo
        seasonality_mode = data.get("seasonality_mode", "multiplicative")
        seasonal_smooth = float(data.get("seasonal_smooth", 0.7))  # Corrigido de seasonal_alpha para seasonal_smooth
        
        # Par√¢metros de intervalo de confian√ßa
        confidence_level = float(data.get("confidence_level", 0.95))
        confidence_factor = float(data.get("confidence_factor", 0.7))
        
        # Par√¢metros de ajuste de valores
        growth_factor = float(data.get("growth_factor", 1.0))
        
        # Ajustes espec√≠ficos por m√™s
        month_adjustments = data.get("month_adjustments", {})
        if isinstance(month_adjustments, str):
            try:
                month_adjustments = json.loads(month_adjustments)
            except Exception as e:
                logger.warning(f"Erro ao processar ajustes por m√™s: {e}")
                month_adjustments = {}
        
        # Converter chaves string para inteiros, se necess√°rio
        if month_adjustments and all(isinstance(k, str) for k in month_adjustments.keys()):
            month_adjustments = {int(k): float(v) for k, v in month_adjustments.items()}
            
        # Ajustes espec√≠ficos por dia da semana
        day_of_week_adjustments = data.get("day_of_week_adjustments", {})
        if isinstance(day_of_week_adjustments, str):
            try:
                day_of_week_adjustments = json.loads(day_of_week_adjustments)
            except Exception as e:
                logger.warning(f"Erro ao processar ajustes por dia da semana: {e}")
                day_of_week_adjustments = {}
        
        # Converter chaves string para inteiros, se necess√°rio
        if day_of_week_adjustments and all(isinstance(k, str) for k in day_of_week_adjustments.keys()):
            day_of_week_adjustments = {int(k): float(v) for k, v in day_of_week_adjustments.items()}
        
        logger.info(f"Aplicando fator de crescimento: {growth_factor}")
        if month_adjustments:
            logger.info(f"Ajustes espec√≠ficos por m√™s: {month_adjustments}")
        if day_of_week_adjustments:
            # Converter n√∫meros de dias para nomes para melhor legibilidade no log
            dias_semana = {0: 'Segunda', 1: 'Ter√ßa', 2: 'Quarta', 3: 'Quinta', 4: 'Sexta', 5: 'S√°bado', 6: 'Domingo'}
            ajustes_legivel = {dias_semana.get(int(k), k): v for k, v in day_of_week_adjustments.items()}
            logger.info(f"Ajustes espec√≠ficos por dia da semana: {ajustes_legivel}")
        
        # Configura√ß√µes de feriados
        feriados_enabled = data.get("feriados_enabled", True)
        feriados_adjustments = data.get("feriados_adjustments", {})
        anos_feriados = data.get("anos_feriados", None)
        
        logger.info(f"Feriados habilitados: {feriados_enabled}")
        if feriados_adjustments:
            logger.info(f"Ajustes para feriados: {feriados_adjustments}")
        if anos_feriados:
            logger.info(f"Anos de feriados: {anos_feriados}")
            
        # Configura√ß√µes de explicabilidade
        include_explanation = data.get("include_explanation", False)
        explanation_level = data.get("explanation_level", "basic")
        explanation_language = data.get("explanation_language", "pt")
        html_layout = data.get("html_layout", "full")  # NOVO: Layout do HTML
        
        # Validar par√¢metros de explicabilidade
        if explanation_level not in ["basic", "detailed", "advanced"]:
            explanation_level = "basic"
            logger.warning(f"explanation_level inv√°lido, usando 'basic'")
            
        if explanation_language not in ["pt", "en"]:
            explanation_language = "pt"
            logger.warning(f"explanation_language inv√°lido, usando 'pt'")
            
        if html_layout not in ["full", "compact"]:
            html_layout = "full"
            logger.warning(f"html_layout inv√°lido, usando 'full'")
            
        logger.info(f"Explica√ß√µes habilitadas: {include_explanation}")
        if include_explanation:
            logger.info(f"N√≠vel de explica√ß√£o: {explanation_level}")
            logger.info(f"Idioma das explica√ß√µes: {explanation_language}")
            logger.info(f"Layout HTML: {html_layout}")
            
        if agrupamento_trimestral:
            logger.info(f"MODO TRIMESTRAL ATIVADO - Per√≠odos interpretados como trimestres")
        elif agrupamento_semestral:
            logger.info(f"MODO SEMESTRAL ATIVADO - Per√≠odos interpretados como semestres")
        
        # Criar e treinar o modelo
        model = ModeloAjustado(
            granularity=gran, 
            seasonality_mode=seasonality_mode,
            seasonal_smooth=seasonal_smooth,
            outlier_threshold=2.5,  # Default sens√≠vel para detectar outliers
            trend_window=3,  # Janela de m√©dia m√≥vel para suavizar tend√™ncia
            confidence_level=confidence_level,
            confidence_factor=confidence_factor,
            growth_factor=growth_factor,
            month_adjustments=month_adjustments,
            day_of_week_adjustments=day_of_week_adjustments,
            feriados_enabled=feriados_enabled,
            feriados_adjustments=feriados_adjustments,
            anos_feriados=anos_feriados,
            include_explanation=include_explanation,
            explanation_level=explanation_level,
            explanation_language=explanation_language,
            html_layout=html_layout
        )
        
        model.fit_multiple(items_data)
        
        # Gera previs√µes para todos os itens
        item_ids = list(items_data.keys())
        
        # Escolher m√©todo de previs√£o baseado no agrupamento solicitado
        if agrupamento_trimestral:
            forecast_results = model.predict_quarterly_multiple(
                items=item_ids,
                start_date=start_date.strftime("%Y-%m-%d"),
                periods=periods  # per√≠odos = n√∫mero de trimestres
            )
        elif agrupamento_semestral:
            forecast_results = model.predict_semiannually_multiple(
                items=item_ids,
                start_date=start_date.strftime("%Y-%m-%d"),
                periods=periods  # per√≠odos = n√∫mero de semestres
            )
        else:
            forecast_results = model.predict_multiple(
                items=item_ids, 
                start_date=start_date.strftime("%Y-%m-%d"), 
                periods=periods
            )
        
        # Log COMPLETO da sa√≠da
        logger.info("="*80)
        logger.info("RESULTADOS COMPLETOS DA PREVIS√ÉO:")
        logger.info("-"*80)
        logger.info(f"Total de previs√µes geradas: {len(forecast_results)}")
        tipo_agrupamento = "Trimestral" if agrupamento_trimestral else "Semestral" if agrupamento_semestral else "Individual"
        logger.info(f"Tipo de agrupamento: {tipo_agrupamento}")
        
        # Salvar resultados completos em um arquivo JSON (com info adicional para logs)
        output_data_for_logs = {
            "forecast": forecast_results,
            "agrupamento_trimestral": agrupamento_trimestral,
            "agrupamento_semestral": agrupamento_semestral
        }
        with open('resultados_completos.json', 'w', encoding='utf-8') as f:
            json.dump(output_data_for_logs, f, ensure_ascii=False, indent=4)
        logger.info(f"Resultados completos salvos em 'resultados_completos.json'")
        
        # Agrupar por item_id para um log mais organizado
        results_by_item = {}
        for result in forecast_results:
            item_id = result["item_id"]
            if item_id not in results_by_item:
                results_by_item[item_id] = []
            results_by_item[item_id].append(result)
        
        # Log COMPLETO por item
        for item_id, forecasts in results_by_item.items():
            if agrupamento_trimestral:
                period_type = "trimestres"
            elif agrupamento_semestral:
                period_type = "semestres"
            else:
                period_type = "per√≠odos"
            logger.info(f"\nItem {item_id}: {len(forecasts)} {period_type} previstos")
            logger.info(f"TODOS OS {period_type.upper()} PARA ITEM {item_id}:")
            logger.info(json.dumps(forecasts, indent=2))
            
            # An√°lise estat√≠stica dos resultados
            if forecasts:
                yhats = [f['yhat'] for f in forecasts]
                
                if agrupamento_trimestral:
                    logger.info(f"\nEstat√≠sticas das previs√µes trimestrais para item {item_id}:")
                    logger.info(f"  Valor m√≠nimo previsto por trimestre: {min(yhats)}")
                    logger.info(f"  Valor m√°ximo previsto por trimestre: {max(yhats)}")
                    logger.info(f"  Valor m√©dio por trimestre: {sum(yhats)/len(yhats):.2f}")
                    logger.info(f"  Total previsto para todos os trimestres: {sum(yhats):.2f}")
                elif agrupamento_semestral:
                    logger.info(f"\nEstat√≠sticas das previs√µes semestrais para item {item_id}:")
                    logger.info(f"  Valor m√≠nimo previsto por semestre: {min(yhats)}")
                    logger.info(f"  Valor m√°ximo previsto por semestre: {max(yhats)}")
                    logger.info(f"  Valor m√©dio por semestre: {sum(yhats)/len(yhats):.2f}")
                    logger.info(f"  Total previsto para todos os semestres: {sum(yhats):.2f}")
                else:
                    trends = [f['trend'] for f in forecasts]
                    yearlys = [f['yearly'] for f in forecasts]
                    
                    logger.info(f"\nEstat√≠sticas das previs√µes para item {item_id}:")
                    logger.info(f"  Valor m√≠nimo previsto: {min(yhats)}")
                    logger.info(f"  Valor m√°ximo previsto: {max(yhats)}")
                    logger.info(f"  Valor m√©dio previsto: {sum(yhats)/len(yhats):.2f}")
                    logger.info(f"  Tend√™ncia inicial: {trends[0]}")
                    logger.info(f"  Tend√™ncia final: {trends[-1]}")
                    logger.info(f"  Varia√ß√£o da tend√™ncia: {trends[-1] - trends[0]:.2f} ({(trends[-1]/trends[0]-1)*100:.2f}%)")
                    logger.info(f"  Contribui√ß√£o sazonal m√≠nima: {min(yearlys)}")
                    logger.info(f"  Contribui√ß√£o sazonal m√°xima: {max(yearlys)}")
        
        logger.info("="*80)
        logger.info("Previs√£o conclu√≠da com sucesso")
        
        # Salvar tanto a entrada quanto a sa√≠da em um √∫nico arquivo para refer√™ncia
        combined_data = {
            "input": data,
            "output": output_data_for_logs
        }
        with open('dados_completos_input_output.json', 'w', encoding='utf-8') as f:
            json.dump(combined_data, f, ensure_ascii=False, indent=4)
        logger.info(f"Dados completos de entrada e sa√≠da salvos em 'dados_completos_input_output.json'")
        
        # MANTER COMPATIBILIDADE: Retornar apenas {"forecast": [...]} como antes
        return jsonify({"forecast": forecast_results})
    
    except Exception as ex:
        logger.error(f"Erro ao processar previs√£o: {str(ex)}")
        logger.error(traceback.format_exc())
        return jsonify({"error": f"Falha na previs√£o: {str(ex)}"}), 500

@app.route('/predict_quarterly', methods=['POST'])
def predict_quarterly():
    """
    Endpoint dedicado para previs√µes trimestrais (agrupadas por 3 em 3 meses)
    
    Par√¢metros esperados:
    - sales_data: Lista de registros de vendas
    - data_inicio: Data de in√≠cio das previs√µes (YYYY-MM-DD)
    - trimestres: N√∫mero de trimestres para prever
    - Outros par√¢metros opcionais (mesmos do endpoint principal)
    """
    data = request.get_json(force=True) or {}
    
    logger.info("="*80)
    logger.info("ENDPOINT DEDICADO PARA PREVIS√ïES TRIMESTRAIS")
    logger.info("="*80)
    
    # For√ßar configura√ß√µes para previs√£o trimestral
    data["granularidade"] = "M"  # Sempre mensal para trimestres
    data["agrupamento_trimestral"] = True
    data["agrupamento_semestral"] = False  # Garantir que n√£o conflite
    
    # Converter 'trimestres' para 'periodos' se fornecido
    if "trimestres" in data:
        data["periodos"] = data["trimestres"]
        logger.info(f"Convertendo 'trimestres' ({data['trimestres']}) para 'periodos'")
    
    # Chamar o endpoint principal com as configura√ß√µes for√ßadas
    # O endpoint predict() j√° retorna no formato compat√≠vel {"forecast": [...]}
    return predict()

@app.route('/predict_semiannually', methods=['POST'])
def predict_semiannually():
    """
    Endpoint dedicado para previs√µes semestrais (agrupadas por 6 em 6 meses)
    
    Par√¢metros esperados:
    - sales_data: Lista de registros de vendas
    - data_inicio: Data de in√≠cio das previs√µes (YYYY-MM-DD)
    - semestres: N√∫mero de semestres para prever
    - Outros par√¢metros opcionais (mesmos do endpoint principal)
    """
    data = request.get_json(force=True) or {}
    
    logger.info("="*80)
    logger.info("ENDPOINT DEDICADO PARA PREVIS√ïES SEMESTRAIS")
    logger.info("="*80)
    
    # For√ßar configura√ß√µes para previs√£o semestral
    data["granularidade"] = "M"  # Sempre mensal para semestres
    data["agrupamento_semestral"] = True
    data["agrupamento_trimestral"] = False  # Garantir que n√£o conflite
    
    # Converter 'semestres' para 'periodos' se fornecido
    if "semestres" in data:
        data["periodos"] = data["semestres"]
        logger.info(f"Convertendo 'semestres' ({data['semestres']}) para 'periodos'")
    
    # Chamar o endpoint principal com as configura√ß√µes for√ßadas
    # O endpoint predict() j√° retorna no formato compat√≠vel {"forecast": [...]}
    return predict()

@app.route('/generate_html', methods=['POST'])
def generate_html():
    """
    Endpoint dedicado para gerar HTML a partir dos dados de explica√ß√£o
    
    Par√¢metros esperados:
    - item_id: ID do item
    - prediction: Dados da previs√£o (yhat, yhat_lower, yhat_upper, trend, yearly, ds)
    - explanation_data: Dados de explica√ß√£o (summary, components, etc.)
    - layout: "full" ou "compact" (padr√£o: "full")
    - is_quarterly: Se √© previs√£o trimestral (padr√£o: false)
    - quarterly_info: Informa√ß√µes do trimestre (se aplic√°vel)
    - is_semiannual: Se √© previs√£o semestral (padr√£o: false)
    - semiannual_info: Informa√ß√µes do semestre (se aplic√°vel)
    - return_html_direct: True para retornar HTML puro (padr√£o: False = JSON)
    
    Headers:
    - Accept: text/html -> retorna HTML puro para exibi√ß√£o direta no navegador
    - Accept: application/json -> retorna JSON com HTML (padr√£o)
    """
    try:
        data = request.get_json(force=True) or {}
        
        logger.info("="*60)
        logger.info("ENDPOINT GERADOR DE HTML")
        logger.info("="*60)
        
        # Verificar se cliente quer HTML direto
        wants_html_direct = (
            request.headers.get('Accept', '').startswith('text/html') or
            data.get('return_html_direct', False)
        )
        
        logger.info(f"Modo retorno: {'HTML direto' if wants_html_direct else 'JSON'}")
        
        # Verificar se foi enviado html_data (modo simplificado) ou par√¢metros individuais
        if 'html_data' in data:
            # Modo simplificado: usar dados do banco
            html_data_from_db = data['html_data']
            layout = data.get('layout', 'full')
            
            logger.info(f"Modo simplificado: usando html_data do banco")
            logger.info(f"Layout: {layout}")
            
            # Extrair dados do html_data
            item_id = html_data_from_db['item_id']
            prediction = html_data_from_db['prediction']
            explanation_data = html_data_from_db['explanation_data']
            is_quarterly = html_data_from_db.get('is_quarterly', False)
            quarterly_info = html_data_from_db.get('quarterly_info')
            is_semiannual = html_data_from_db.get('is_semiannual', False)
            semiannual_info = html_data_from_db.get('semiannual_info')
            
            # Converter data ISO de volta para pd.Timestamp
            try:
                date = pd.to_datetime(html_data_from_db['date_iso'])
            except Exception as e:
                if wants_html_direct:
                    return f"<html><body><h1>Erro: Data inv√°lida em html_data: {str(e)}</h1></body></html>", 400, {'Content-Type': 'text/html; charset=utf-8'}
                return jsonify({"error": f"Data inv√°lida em html_data: {str(e)}"}), 400
                
        else:
            # Modo completo: validar par√¢metros individuais
            required_fields = ['item_id', 'prediction']
            for field in required_fields:
                if field not in data:
                    if wants_html_direct:
                        return f"<html><body><h1>Erro: Campo obrigat√≥rio '{field}' n√£o fornecido</h1></body></html>", 400, {'Content-Type': 'text/html; charset=utf-8'}
                    return jsonify({"error": f"Campo obrigat√≥rio '{field}' n√£o fornecido"}), 400
            
            # Extrair par√¢metros individuais
            item_id = data['item_id']
            prediction = data['prediction']
            explanation_data = data.get('explanation_data', {})
            layout = data.get('layout', 'full')
            is_quarterly = data.get('is_quarterly', False)
            quarterly_info = data.get('quarterly_info')
            is_semiannual = data.get('is_semiannual', False)
            semiannual_info = data.get('semiannual_info')
            
            # Converter data string para pd.Timestamp
            try:
                date = pd.to_datetime(prediction['ds'])
            except Exception as e:
                if wants_html_direct:
                    return f"<html><body><h1>Erro: Data inv√°lida em 'prediction.ds': {str(e)}</h1></body></html>", 400, {'Content-Type': 'text/html; charset=utf-8'}
                return jsonify({"error": f"Data inv√°lida em 'prediction.ds': {str(e)}"}), 400
        
        # Validar layout
        if layout not in ['full', 'compact']:
            layout = 'full'
            logger.warning(f"Layout inv√°lido, usando 'full'")
        
        # Validar prediction apenas no modo completo
        if 'html_data' not in data:
            required_prediction_fields = ['yhat', 'yhat_lower', 'yhat_upper', 'trend', 'yearly', 'ds']
            for field in required_prediction_fields:
                if field not in prediction:
                    if wants_html_direct:
                        return f"<html><body><h1>Erro: Campo obrigat√≥rio 'prediction.{field}' n√£o fornecido</h1></body></html>", 400, {'Content-Type': 'text/html; charset=utf-8'}
                    return jsonify({"error": f"Campo obrigat√≥rio 'prediction.{field}' n√£o fornecido"}), 400
        
        logger.info(f"Gerando HTML para item {item_id}")
        logger.info(f"Layout: {layout}")
        logger.info(f"Trimestral: {is_quarterly}")
        logger.info(f"Semestral: {is_semiannual}")
        
        # Criar um modelo tempor√°rio apenas para acessar as fun√ß√µes de gera√ß√£o de HTML
        # Recuperar configura√ß√µes salvas no explanation_data
        seasonality_mode = explanation_data.get('seasonality_mode', 'multiplicative')
        freq = explanation_data.get('freq', 'MS')
        month_adjustments = explanation_data.get('month_adjustments', {})
        day_of_week_adjustments = explanation_data.get('day_of_week_adjustments', {})
        growth_factor = explanation_data.get('growth_factor', 1.0)
        confidence_level = explanation_data.get('confidence_level', 0.95)
        
        logger.info(f"Configura√ß√µes recuperadas:")
        logger.info(f"  seasonality_mode: {seasonality_mode}")
        logger.info(f"  freq: {freq}")
        logger.info(f"  month_adjustments: {month_adjustments}")
        
        # Debug: verificar seasonal_pattern
        seasonal_pattern = explanation_data.get('seasonal_pattern', {})
        logger.info(f"  seasonal_pattern: {seasonal_pattern}")
        if seasonal_pattern:
            logger.info(f"  Fator para m√™s {date.month}: {seasonal_pattern.get(date.month, 'N√ÉO ENCONTRADO')}")
        
        # Debug: verificar prediction
        logger.info(f"Dados da previs√£o:")
        logger.info(f"  Data: {date}")
        logger.info(f"  M√™s: {date.month}")
        logger.info(f"  Trend: {prediction.get('trend')}")
        logger.info(f"  Yearly: {prediction.get('yearly')}")
        logger.info(f"  Yhat: {prediction.get('yhat')}")
        
        modelo_temp = ModeloAjustado(
            granularity='M',
            seasonality_mode=seasonality_mode,
            include_explanation=True,
            explanation_level='detailed',
            explanation_language='pt',
            html_layout=layout,
            month_adjustments=month_adjustments,
            day_of_week_adjustments=day_of_week_adjustments,
            growth_factor=growth_factor,
            confidence_level=confidence_level
        )
        
        # Criar dados completos do modelo e m√©tricas (simulados a partir dos dados de explica√ß√£o)
        model_data = {
            'b': explanation_data.get('trend_slope', 0),  # Slope da tend√™ncia
            'seasonal_pattern': explanation_data.get('seasonal_pattern', {}),
            'day_of_week_pattern': explanation_data.get('day_of_week_pattern', {}),
            'mean': prediction.get('yhat', 100),
            'std': explanation_data.get('std', 10),
            'baseline': explanation_data.get('model_baseline', prediction.get('trend', 100) * 0.5)
        }
        
        metrics_data = {
            'data_points': explanation_data.get('data_points', 12),
            'confidence_score': explanation_data.get('confidence_score', 'M√©dia'),
            'mape': explanation_data.get('mape', 15.0),
            'r2': explanation_data.get('r2', 0.7),
            'outlier_count': explanation_data.get('outlier_count', 0),
            'data_completeness': explanation_data.get('data_completeness', 100.0),
            'seasonal_strength': explanation_data.get('seasonal_strength', 0.3),
            'trend_strength': explanation_data.get('trend_strength', 0.2),
            'training_period': explanation_data.get('training_period', {
                'start': '2023-01-01',
                'end': '2023-12-01'
            })
        }
        
        # Armazenar temporariamente no modelo (necess√°rio para as fun√ß√µes internas)
        modelo_temp.models[item_id] = model_data
        modelo_temp.quality_metrics[item_id] = metrics_data
        
        # Determinar informa√ß√µes do per√≠odo
        if is_quarterly and quarterly_info:
            period_name = quarterly_info.get('quarter_name', f"Q{((date.month - 1) // 3) + 1}/{date.year}")
            period_type = "trimestre"
        elif is_semiannual and semiannual_info:
            period_name = semiannual_info.get('semester_name', f"S{1 if date.month <= 6 else 2}/{date.year}")
            period_type = "semestre"
        else:
            month_name = modelo_temp._get_month_name_pt(date.month)
            period_name = f"{month_name}/{date.year}"
            period_type = "m√™s"
        
        # An√°lise de confian√ßa
        confidence = metrics_data['confidence_score']
        confidence_color = "#28a745" if confidence == "Alta" else "#ffc107" if confidence == "M√©dia" else "#dc3545"
        
        # Gerar HTML usando as fun√ß√µes internas
        if layout == "compact":
            html_content = modelo_temp._generate_compact_html(
                item_id, prediction, date, is_quarterly, quarterly_info, is_semiannual, semiannual_info,
                model_data, metrics_data, period_name, period_type, 
                confidence, confidence_color
            )
        else:
            html_content = modelo_temp._generate_html_summary(
                item_id, prediction, date, is_quarterly, quarterly_info, is_semiannual, semiannual_info, layout
            )
        
        logger.info(f"HTML gerado com sucesso: {len(html_content)} caracteres")
        logger.info("="*60)
        
        # Retornar HTML direto ou JSON baseado na prefer√™ncia do cliente
        if wants_html_direct:
            # Retornar HTML puro para exibi√ß√£o direta no navegador
            logger.info("Retornando HTML direto (text/html)")
            return html_content, 200, {'Content-Type': 'text/html; charset=utf-8'}
        else:
            # Retornar JSON (comportamento padr√£o)
            logger.info("Retornando JSON com HTML")
            return jsonify({
                "html": html_content,
                "info": {
                    "layout": layout,
                    "size_chars": len(html_content),
                    "is_quarterly": is_quarterly,
                    "is_semiannual": is_semiannual,
                    "item_id": item_id,
                    "period": period_name
                }
            })
        
    except Exception as ex:
        logger.error(f"Erro ao gerar HTML: {str(ex)}")
        logger.error(traceback.format_exc())
        
        # Tratar erros baseado na prefer√™ncia do cliente
        if request.headers.get('Accept', '').startswith('text/html') or request.get_json(force=True, silent=True, cache=False).get('return_html_direct', False):
            return f"<html><body><h1>Erro interno: {str(ex)}</h1><p>Detalhes t√©cnicos ocultos por seguran√ßa.</p></body></html>", 500, {'Content-Type': 'text/html; charset=utf-8'}
        else:
            return jsonify({"error": f"Falha na gera√ß√£o de HTML: {str(ex)}"}), 500

@app.route('/mrp_optimize', methods=['POST'])
def mrp_optimize():
    """
    Endpoint para otimiza√ß√£o MRP usando algoritmos inteligentes de supply chain
    
    Par√¢metros esperados:
    - daily_demands: Dict com demandas di√°rias {"YYYY-MM": demanda_m√©dia_di√°ria}
    - initial_stock: Estoque inicial (float)
    - leadtime_days: Lead time em dias (int)
    - period_start_date: Data in√≠cio do per√≠odo (YYYY-MM-DD)
    - period_end_date: Data fim do per√≠odo (YYYY-MM-DD)
    - start_cutoff_date: Data de corte inicial (YYYY-MM-DD)
    - end_cutoff_date: Data de corte final (YYYY-MM-DD)
    
    Par√¢metros opcionais de otimiza√ß√£o:
    - setup_cost: Custo fixo por pedido (padr√£o: 250.0)
    - holding_cost_rate: Taxa de custo de manuten√ß√£o (padr√£o: 0.20)
    - stockout_cost_multiplier: Multiplicador de custo de falta (padr√£o: 2.5)
    - service_level: N√≠vel de servi√ßo desejado (padr√£o: 0.95)
    - min_batch_size: Tamanho m√≠nimo do lote (padr√£o: 50.0)
    - max_batch_size: Tamanho m√°ximo do lote (padr√£o: 10000.0)
    - review_period_days: Per√≠odo de revis√£o em dias (padr√£o: 7)
    - safety_days: Dias de seguran√ßa adicional (padr√£o: 3)
    - consolidation_window_days: Janela para consolidar pedidos (padr√£o: 5)
    - daily_production_capacity: Capacidade di√°ria de produ√ß√£o (padr√£o: infinito)
    - enable_eoq_optimization: Habilitar otimiza√ß√£o EOQ (padr√£o: True)
    - enable_consolidation: Habilitar consolida√ß√£o de pedidos (padr√£o: True)
    - ignore_safety_stock: Ignorar completamente estoque de seguran√ßa (padr√£o: False)
    - exact_quantity_match: Produzir exatamente a demanda sem arredondamentos (padr√£o: False)
    """
    try:
        data = request.get_json(force=True) or {}
        
        logger.info("="*80)
        logger.info("ENDPOINT MRP OPTIMIZATION")
        logger.info("="*80)
        
        # Log dos dados de entrada
        logger.info("DADOS DE ENTRADA:")
        logger.info(f"daily_demands: {data.get('daily_demands', 'n√£o informado')}")
        logger.info(f"initial_stock: {data.get('initial_stock', 'n√£o informado')}")
        logger.info(f"leadtime_days: {data.get('leadtime_days', 'n√£o informado')}")
        logger.info(f"period_start_date: {data.get('period_start_date', 'n√£o informado')}")
        logger.info(f"period_end_date: {data.get('period_end_date', 'n√£o informado')}")
        logger.info(f"start_cutoff_date: {data.get('start_cutoff_date', 'n√£o informado')}")
        logger.info(f"end_cutoff_date: {data.get('end_cutoff_date', 'n√£o informado')}")
        logger.info(f"ignore_safety_stock: {data.get('ignore_safety_stock', 'n√£o informado')}")
        logger.info(f"exact_quantity_match: {data.get('exact_quantity_match', 'n√£o informado')}")
        
        # Valida√ß√µes dos par√¢metros obrigat√≥rios
        required_fields = [
            'daily_demands', 'initial_stock', 'leadtime_days',
            'period_start_date', 'period_end_date', 
            'start_cutoff_date', 'end_cutoff_date'
        ]
        
        for field in required_fields:
            if field not in data:
                return jsonify({"error": f"Campo obrigat√≥rio '{field}' n√£o fornecido"}), 400
        
        # Validar tipos de dados
        try:
            initial_stock = float(data['initial_stock'])
            leadtime_days = int(data['leadtime_days'])
        except (ValueError, TypeError):
            return jsonify({"error": "initial_stock deve ser n√∫mero e leadtime_days deve ser inteiro"}), 400
        
        if initial_stock < 0:
            return jsonify({"error": "initial_stock n√£o pode ser negativo"}), 400
            
        if leadtime_days < 0:
            return jsonify({"error": "leadtime_days n√£o pode ser negativo"}), 400
        
        # Validar daily_demands
        daily_demands = data['daily_demands']
        if not isinstance(daily_demands, dict) or not daily_demands:
            return jsonify({"error": "daily_demands deve ser dicion√°rio n√£o vazio"}), 400
        
        # Validar formato das demandas
        for date_key, demand_value in daily_demands.items():
            try:
                # Verificar formato da data (YYYY-MM)
                pd.to_datetime(date_key + '-01')
                # Verificar se demanda √© num√©rica
                float(demand_value)
            except:
                return jsonify({"error": f"Formato inv√°lido em daily_demands. Chave '{date_key}' deve ser YYYY-MM e valor deve ser num√©rico"}), 400
        
        # Validar datas
        try:
            period_start_date = data['period_start_date']
            period_end_date = data['period_end_date']
            start_cutoff_date = data['start_cutoff_date']
            end_cutoff_date = data['end_cutoff_date']
            
            # Validar formato das datas
            pd.to_datetime(period_start_date)
            pd.to_datetime(period_end_date)
            pd.to_datetime(start_cutoff_date)
            pd.to_datetime(end_cutoff_date)
            
        except:
            return jsonify({"error": "Datas devem estar no formato YYYY-MM-DD"}), 400
        
        # Extrair par√¢metros opcionais de otimiza√ß√£o
        optimization_kwargs = {}
        optional_params = [
            'setup_cost', 'holding_cost_rate', 'stockout_cost_multiplier',
            'service_level', 'min_batch_size', 'max_batch_size',
            'review_period_days', 'safety_days', 'consolidation_window_days',
            'daily_production_capacity', 'enable_eoq_optimization', 'enable_consolidation',
            'include_extended_analytics',
            'ignore_safety_stock',  # üéØ NOVO: Ignorar completamente estoque de seguran√ßa
            'exact_quantity_match',  # üéØ NOVO: Produzir exatamente a demanda sem arredondamentos
            'auto_calculate_max_batch_size',  # üéØ NOVO: Auto-calculation do max_batch_size
            'max_batch_multiplier'  # üéØ NOVO: Multiplicador do EOQ para auto-calculation
        ]
        
        for param in optional_params:
            if param in data:
                optimization_kwargs[param] = data[param]
        
        # Log dos par√¢metros opcionais
        if optimization_kwargs:
            logger.info("PAR√ÇMETROS DE OTIMIZA√á√ÉO CUSTOMIZADOS:")
            for param, value in optimization_kwargs.items():
                logger.info(f"  {param}: {value}")
        
        # Criar otimizador MRP
        optimizer = MRPOptimizer()
        
        # Executar otimiza√ß√£o
        logger.info("Iniciando otimiza√ß√£o MRP...")
        result = optimizer.calculate_batches_with_start_end_cutoff(
            daily_demands=daily_demands,
            initial_stock=initial_stock,
            leadtime_days=leadtime_days,
            period_start_date=period_start_date,
            period_end_date=period_end_date,
            start_cutoff_date=start_cutoff_date,
            end_cutoff_date=end_cutoff_date,
            **optimization_kwargs
        )
        
        # Log dos resultados
        logger.info("OTIMIZA√á√ÉO MRP CONCLU√çDA:")
        logger.info(f"Total de lotes planejados: {len(result['batches'])}")
        logger.info(f"Produ√ß√£o total: {result['analytics']['summary']['total_produced']}")
        logger.info(f"Taxa de cobertura: {result['analytics']['summary']['production_coverage_rate']}")
        logger.info(f"Estoque m√≠nimo: {result['analytics']['summary']['minimum_stock']}")
        logger.info(f"Estoque final: {result['analytics']['summary']['final_stock']}")
        logger.info(f"Stockout ocorreu: {result['analytics']['summary']['stockout_occurred']}")
        
        # Salvar resultados completos para debug
        with open('mrp_results_completos.json', 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=4)
        logger.info("Resultados MRP salvos em 'mrp_results_completos.json'")
        
        # Log detalhado dos primeiros lotes
        if result['batches']:
            logger.info("\nPRIMEIROS LOTES PLANEJADOS:")
            for i, batch in enumerate(result['batches'][:5]):  # Mostrar at√© 5 primeiros
                logger.info(f"  Lote {i+1}:")
                logger.info(f"    Data pedido: {batch['order_date']}")
                logger.info(f"    Data chegada: {batch['arrival_date']}")
                logger.info(f"    Quantidade: {batch['quantity']}")
                logger.info(f"    Urg√™ncia: {batch['analytics'].get('urgency_level', 'N/A')}")
                logger.info(f"    Cobertura: {batch['analytics'].get('coverage_days', 'N/A')} dias")
        
        logger.info("="*80)
        
        # Converter tipos numpy para tipos nativos do Python para serializa√ß√£o JSON
        def convert_numpy_types(obj):
            """Converte tipos numpy para tipos nativos do Python"""
            if isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            elif hasattr(obj, 'item'):  # numpy scalar
                return obj.item()
            elif hasattr(obj, 'tolist'):  # numpy array
                return obj.tolist()
            else:
                return obj
        
        result_converted = convert_numpy_types(result)
        
        return jsonify(result_converted)
        
    except Exception as ex:
        logger.error(f"Erro na otimiza√ß√£o MRP: {str(ex)}")
        logger.error(traceback.format_exc())
        return jsonify({"error": f"Falha na otimiza√ß√£o MRP: {str(ex)}"}), 500

@app.route('/mrp_sporadic', methods=['POST'])
def mrp_sporadic():
    """
    Endpoint para planejamento de lotes para demandas espor√°dicas
    
    Par√¢metros obrigat√≥rios:
    - sporadic_demand: Dict com demandas espor√°dicas {"YYYY-MM-DD": quantidade}
    - initial_stock: Estoque inicial (float)
    - leadtime_days: Lead time em dias (int)
    - period_start_date: Data in√≠cio do per√≠odo (YYYY-MM-DD)
    - period_end_date: Data fim do per√≠odo (YYYY-MM-DD)
    - start_cutoff_date: Data de corte inicial (YYYY-MM-DD)
    - end_cutoff_date: Data de corte final (YYYY-MM-DD)
    
    Par√¢metros opcionais:
    - safety_margin_percent: Margem de seguran√ßa % (padr√£o: 8.0)
    - safety_days: Dias de seguran√ßa (padr√£o: 2)
    - minimum_stock_percent: Estoque m√≠nimo % da maior demanda (padr√£o: 0.0)
    - max_gap_days: Gap m√°ximo entre lotes (padr√£o: 999)
    
    Par√¢metros avan√ßados de otimiza√ß√£o (mesmos do MRP):
    - setup_cost: Custo fixo por pedido (padr√£o: 250.0)
    - holding_cost_rate: Taxa de custo de manuten√ß√£o (padr√£o: 0.20)
    - service_level: N√≠vel de servi√ßo desejado (padr√£o: 0.95)
    - min_batch_size: Tamanho m√≠nimo do lote (padr√£o: 200.0)
    - max_batch_size: Tamanho m√°ximo do lote (padr√£o: 10000.0)
    - enable_consolidation: Habilitar consolida√ß√£o de pedidos (padr√£o: True)
    - enable_eoq_optimization: Habilitar otimiza√ß√£o EOQ (padr√£o: True)
    """
    try:
        data = request.get_json(force=True) or {}
        
        logger.info("="*80)
        logger.info("ENDPOINT MRP SPORADIC DEMAND")
        logger.info("="*80)
        
        # Log dos dados de entrada
        logger.info("DADOS DE ENTRADA:")
        logger.info(f"sporadic_demand: {data.get('sporadic_demand', 'n√£o informado')}")
        logger.info(f"initial_stock: {data.get('initial_stock', 'n√£o informado')}")
        logger.info(f"leadtime_days: {data.get('leadtime_days', 'n√£o informado')}")
        logger.info(f"period_start_date: {data.get('period_start_date', 'n√£o informado')}")
        logger.info(f"period_end_date: {data.get('period_end_date', 'n√£o informado')}")
        logger.info(f"start_cutoff_date: {data.get('start_cutoff_date', 'n√£o informado')}")
        logger.info(f"end_cutoff_date: {data.get('end_cutoff_date', 'n√£o informado')}")
        
        # Valida√ß√µes dos par√¢metros obrigat√≥rios
        required_fields = [
            'sporadic_demand', 'initial_stock', 'leadtime_days',
            'period_start_date', 'period_end_date', 
            'start_cutoff_date', 'end_cutoff_date'
        ]
        
        for field in required_fields:
            if field not in data:
                return jsonify({"error": f"Campo obrigat√≥rio '{field}' n√£o fornecido"}), 400
        
        # Validar tipos de dados
        try:
            initial_stock = float(data['initial_stock'])
            leadtime_days = int(data['leadtime_days'])
        except (ValueError, TypeError):
            return jsonify({"error": "initial_stock deve ser n√∫mero e leadtime_days deve ser inteiro"}), 400
        
        if initial_stock < 0:
            return jsonify({"error": "initial_stock n√£o pode ser negativo"}), 400
            
        if leadtime_days < 0:
            return jsonify({"error": "leadtime_days n√£o pode ser negativo"}), 400
        
        # Validar sporadic_demand
        sporadic_demand = data['sporadic_demand']
        if not isinstance(sporadic_demand, dict) or not sporadic_demand:
            return jsonify({"error": "sporadic_demand deve ser dicion√°rio n√£o vazio"}), 400
        
        # Validar formato das demandas espor√°dicas
        for date_key, demand_value in sporadic_demand.items():
            try:
                # Verificar formato da data (YYYY-MM-DD)
                pd.to_datetime(date_key)
                # Verificar se demanda √© num√©rica e positiva
                demand_val = float(demand_value)
                if demand_val < 0:
                    return jsonify({"error": f"Demanda em '{date_key}' n√£o pode ser negativa"}), 400
            except:
                return jsonify({"error": f"Formato inv√°lido em sporadic_demand. Chave '{date_key}' deve ser YYYY-MM-DD e valor deve ser num√©rico positivo"}), 400
        
        # Validar datas
        try:
            period_start_date = data['period_start_date']
            period_end_date = data['period_end_date']
            start_cutoff_date = data['start_cutoff_date']
            end_cutoff_date = data['end_cutoff_date']
            
            # Validar formato das datas
            start_pd = pd.to_datetime(period_start_date)
            end_pd = pd.to_datetime(period_end_date)
            start_cutoff_pd = pd.to_datetime(start_cutoff_date)
            end_cutoff_pd = pd.to_datetime(end_cutoff_date)
            
            # Validar l√≥gica das datas
            if start_pd >= end_pd:
                return jsonify({"error": "period_start_date deve ser anterior a period_end_date"}), 400
            if start_cutoff_pd > end_cutoff_pd:
                return jsonify({"error": "start_cutoff_date deve ser anterior ou igual a end_cutoff_date"}), 400
            
        except:
            return jsonify({"error": "Datas devem estar no formato YYYY-MM-DD"}), 400
        
        # Extrair par√¢metros espec√≠ficos de demanda espor√°dica
        safety_margin_percent = float(data.get('safety_margin_percent', 8.0))
        safety_days = int(data.get('safety_days', 2))
        minimum_stock_percent = float(data.get('minimum_stock_percent', 0.0))
        max_gap_days = int(data.get('max_gap_days', 999))
        
        # Validar par√¢metros espec√≠ficos
        if safety_margin_percent < 0 or safety_margin_percent > 100:
            return jsonify({"error": "safety_margin_percent deve estar entre 0 e 100"}), 400
        if safety_days < 0:
            return jsonify({"error": "safety_days n√£o pode ser negativo"}), 400
        if minimum_stock_percent < 0 or minimum_stock_percent > 100:
            return jsonify({"error": "minimum_stock_percent deve estar entre 0 e 100"}), 400
        if max_gap_days < 1:
            return jsonify({"error": "max_gap_days deve ser pelo menos 1"}), 400
        
        # Extrair par√¢metros avan√ßados de otimiza√ß√£o (opcionais)
        optimization_kwargs = {}
        optional_params = [
            'setup_cost', 'holding_cost_rate', 'stockout_cost_multiplier',
            'service_level', 'min_batch_size', 'max_batch_size',
            'review_period_days', 'consolidation_window_days',
            'daily_production_capacity', 'enable_eoq_optimization', 'enable_consolidation',
            'auto_calculate_max_batch_size',  # üéØ NOVO: Auto-calculation do max_batch_size
            'max_batch_multiplier'  # üéØ NOVO: Multiplicador do EOQ para auto-calculation
        ]
        
        for param in optional_params:
            if param in data:
                optimization_kwargs[param] = data[param]
        
        # Log dos par√¢metros espec√≠ficos
        logger.info("PAR√ÇMETROS ESPEC√çFICOS DE DEMANDA ESPOR√ÅDICA:")
        logger.info(f"  safety_margin_percent: {safety_margin_percent}%")
        logger.info(f"  safety_days: {safety_days}")
        logger.info(f"  minimum_stock_percent: {minimum_stock_percent}%")
        logger.info(f"  max_gap_days: {max_gap_days}")
        
        # Log dos par√¢metros de otimiza√ß√£o (se fornecidos)
        if optimization_kwargs:
            logger.info("PAR√ÇMETROS DE OTIMIZA√á√ÉO AVAN√áADOS:")
            for param, value in optimization_kwargs.items():
                logger.info(f"  {param}: {value}")
        
        # An√°lise pr√©via das demandas
        demand_dates = list(sporadic_demand.keys())
        demand_values = list(sporadic_demand.values())
        total_demand = sum(demand_values)
        max_demand = max(demand_values)
        min_demand = min(demand_values)
        avg_demand = total_demand / len(demand_values)
        
        logger.info("AN√ÅLISE PR√âVIA DAS DEMANDAS ESPOR√ÅDICAS:")
        logger.info(f"  Total de eventos: {len(sporadic_demand)}")
        logger.info(f"  Per√≠odo das demandas: {min(demand_dates)} a {max(demand_dates)}")
        logger.info(f"  Demanda total: {total_demand}")
        logger.info(f"  Demanda m√©dia por evento: {avg_demand:.2f}")
        logger.info(f"  Demanda m√≠nima: {min_demand}")
        logger.info(f"  Demanda m√°xima: {max_demand}")
        logger.info(f"  Varia√ß√£o: {((max_demand - min_demand) / avg_demand * 100):.1f}%")
        
        # Criar otimizador MRP
        optimizer = MRPOptimizer()
        
        # Executar planejamento de demanda espor√°dica
        logger.info("Iniciando planejamento de lotes para demanda espor√°dica...")
        result = optimizer.calculate_batches_for_sporadic_demand(
            sporadic_demand=sporadic_demand,
            initial_stock=initial_stock,
            leadtime_days=leadtime_days,
            period_start_date=period_start_date,
            period_end_date=period_end_date,
            start_cutoff_date=start_cutoff_date,
            end_cutoff_date=end_cutoff_date,
            safety_margin_percent=safety_margin_percent,
            safety_days=safety_days,
            minimum_stock_percent=minimum_stock_percent,
            max_gap_days=max_gap_days,
            **optimization_kwargs
        )
        
        # Log dos resultados
        analytics = result['analytics']
        summary = analytics['summary']
        sporadic_metrics = analytics['sporadic_demand_metrics']
        
        logger.info("PLANEJAMENTO ESPOR√ÅDICO CONCLU√çDO:")
        logger.info(f"Total de lotes planejados: {len(result['batches'])}")
        logger.info(f"Produ√ß√£o total: {summary['total_produced']}")
        logger.info(f"Taxa de cobertura: {summary['production_coverage_rate']}")
        logger.info(f"Taxa de atendimento: {summary['demand_fulfillment_rate']}%")
        logger.info(f"Demandas atendidas: {summary['demands_met_count']}/{summary['demands_met_count'] + summary['demands_unmet_count']}")
        logger.info(f"Estoque m√≠nimo: {summary['minimum_stock']}")
        logger.info(f"Estoque final: {summary['final_stock']}")
        logger.info(f"Stockout ocorreu: {summary['stockout_occurred']}")
        
        logger.info("M√âTRICAS ESPEC√çFICAS DE DEMANDA ESPOR√ÅDICA:")
        logger.info(f"Concentra√ß√£o de demanda: {sporadic_metrics['demand_concentration']['concentration_level']}")
        logger.info(f"Previsibilidade: {sporadic_metrics['demand_predictability']}")
        logger.info(f"Intervalo m√©dio entre demandas: {sporadic_metrics['interval_statistics']['average_interval_days']} dias")
        logger.info(f"Picos de demanda detectados: {sporadic_metrics['peak_demand_analysis']['peak_count']}")
        
        # Salvar resultados completos para debug
        with open('mrp_sporadic_results.json', 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=4)
        logger.info("Resultados salvos em 'mrp_sporadic_results.json'")
        
        # Log detalhado dos lotes com informa√ß√µes espec√≠ficas
        if result['batches']:
            logger.info(f"\nLOTES PLANEJADOS PARA DEMANDAS ESPOR√ÅDICAS:")
            for i, batch in enumerate(result['batches'], 1):
                analytics_batch = batch['analytics']
                logger.info(f"  Lote {i}:")
                logger.info(f"    Data pedido: {batch['order_date']}")
                logger.info(f"    Data chegada: {batch['arrival_date']}")
                logger.info(f"    Quantidade: {batch['quantity']}")
                logger.info(f"    Demanda alvo: {analytics_batch.get('target_demand_date', 'N/A')} ({analytics_batch.get('target_demand_quantity', 'N/A')})")
                logger.info(f"    D√©ficit coberto: {analytics_batch.get('shortfall_covered', 'N/A')}")
                logger.info(f"    Cr√≠tico: {'Sim' if analytics_batch.get('is_critical', False) else 'N√£o'}")
                logger.info(f"    Urg√™ncia: {analytics_batch.get('urgency_level', 'N/A')}")
                logger.info(f"    Margem seguran√ßa: {analytics_batch.get('safety_margin_days', 'N/A')} dias")
                logger.info(f"    Efici√™ncia: {analytics_batch.get('efficiency_ratio', 'N/A')}")
        
        # Log de demandas n√£o atendidas (se houver)
        if summary['unmet_demand_details']:
            logger.info(f"\nDEMANDAS N√ÉO ATENDIDAS ({len(summary['unmet_demand_details'])}):")
            for unmet in summary['unmet_demand_details']:
                logger.info(f"  Data: {unmet['date']}")
                logger.info(f"    Demanda: {unmet['demand']}")
                logger.info(f"    Estoque dispon√≠vel: {unmet['available_stock']}")
                logger.info(f"    D√©ficit: {unmet['shortage']}")
        
        logger.info("="*80)
        
        # Converter tipos numpy para tipos nativos do Python
        def convert_numpy_types(obj):
            """Converte tipos numpy para tipos nativos do Python"""
            if isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            elif hasattr(obj, 'item'):  # numpy scalar
                return obj.item()
            elif hasattr(obj, 'tolist'):  # numpy array
                return obj.tolist()
            else:
                return obj
        
        result_converted = convert_numpy_types(result)
        
        return jsonify(result_converted)
        
    except Exception as ex:
        logger.error(f"Erro no planejamento de demanda espor√°dica: {str(ex)}")
        logger.error(traceback.format_exc())
        return jsonify({"error": f"Falha no planejamento de demanda espor√°dica: {str(ex)}"}), 500

@app.route('/mrp_advanced', methods=['POST'])
def mrp_advanced():
    """
    Endpoint MRP Avan√ßado com Analytics Estendidos
    
    Utiliza algoritmos avan√ßados de supply chain incluindo:
    - EOQ (Economic Order Quantity) calculations
    - ABC/XYZ classification
    - An√°lise de sazonalidade e tend√™ncias
    - M√∫ltiplas estrat√©gias de planejamento
    - Analytics estendidos com m√©tricas de performance
    - Integra√ß√£o com supplychainpy (quando dispon√≠vel)
    """
    try:
        data = request.get_json(force=True) or {}
        
        # Log completo dos dados de entrada
        logger.info("="*80)
        logger.info("MRP AVAN√áADO - DADOS DE ENTRADA:")
        logger.info("-"*80)
        logger.info(f"Endpoint: /mrp_advanced")
        logger.info(f"Method: POST")
        logger.info(f"Data keys: {list(data.keys())}")
        
        # Valida√ß√µes obrigat√≥rias
        required_fields = ['sporadic_demand', 'initial_stock', 'leadtime_days', 
                          'period_start_date', 'period_end_date', 
                          'start_cutoff_date', 'end_cutoff_date']
        
        for field in required_fields:
            if field not in data:
                return jsonify({"error": f"Campo obrigat√≥rio '{field}' n√£o encontrado"}), 400
        
        # Extrair par√¢metros b√°sicos
        initial_stock = float(data['initial_stock'])
        leadtime_days = int(data['leadtime_days'])
        
        # Validar valores b√°sicos
        if initial_stock < 0:
            return jsonify({"error": "initial_stock n√£o pode ser negativo"}), 400
        if leadtime_days < 0:
            return jsonify({"error": "leadtime_days n√£o pode ser negativo"}), 400
        
        # Validar sporadic_demand
        sporadic_demand = data['sporadic_demand'] 
        if not isinstance(sporadic_demand, dict) or not sporadic_demand:
            return jsonify({"error": "sporadic_demand deve ser dicion√°rio n√£o vazio"}), 400
        
        # Validar formato das demandas espor√°dicas
        for date_key, demand_value in sporadic_demand.items():
            try:
                pd.to_datetime(date_key)
                demand_val = float(demand_value)
                if demand_val < 0:
                    return jsonify({"error": f"Demanda em '{date_key}' n√£o pode ser negativa"}), 400
            except:
                return jsonify({"error": f"Formato inv√°lido em sporadic_demand. Chave '{date_key}' deve ser YYYY-MM-DD e valor deve ser num√©rico positivo"}), 400
        
        # Validar datas
        try:
            period_start_date = data['period_start_date']
            period_end_date = data['period_end_date']
            start_cutoff_date = data['start_cutoff_date']
            end_cutoff_date = data['end_cutoff_date']
            
            # Validar formato das datas
            start_pd = pd.to_datetime(period_start_date)
            end_pd = pd.to_datetime(period_end_date)
            start_cutoff_pd = pd.to_datetime(start_cutoff_date)
            end_cutoff_pd = pd.to_datetime(end_cutoff_date)
            
            # Validar l√≥gica das datas
            if start_pd >= end_pd:
                return jsonify({"error": "period_start_date deve ser anterior a period_end_date"}), 400
            if start_cutoff_pd > end_cutoff_pd:
                return jsonify({"error": "start_cutoff_date deve ser anterior ou igual a end_cutoff_date"}), 400
            
        except:
            return jsonify({"error": "Datas devem estar no formato YYYY-MM-DD"}), 400
        
        # Par√¢metros espec√≠ficos de demanda espor√°dica
        safety_margin_percent = float(data.get('safety_margin_percent', 8.0))
        safety_days = int(data.get('safety_days', 2))
        minimum_stock_percent = float(data.get('minimum_stock_percent', 0.0))
        max_gap_days = int(data.get('max_gap_days', 999))
        
        # Validar par√¢metros espec√≠ficos
        if safety_margin_percent < 0 or safety_margin_percent > 100:
            return jsonify({"error": "safety_margin_percent deve estar entre 0 e 100"}), 400
        if safety_days < 0:
            return jsonify({"error": "safety_days n√£o pode ser negativo"}), 400
        if minimum_stock_percent < 0 or minimum_stock_percent > 100:
            return jsonify({"error": "minimum_stock_percent deve estar entre 0 e 100"}), 400
        if max_gap_days < 1:
            return jsonify({"error": "max_gap_days deve ser pelo menos 1"}), 400
        
        # Par√¢metros avan√ßados de otimiza√ß√£o
        optimization_params = OptimizationParams()
        
        # Par√¢metros de custo
        if 'setup_cost' in data:
            optimization_params.setup_cost = float(data['setup_cost'])
        if 'holding_cost_rate' in data:
            optimization_params.holding_cost_rate = float(data['holding_cost_rate'])
        if 'stockout_cost_multiplier' in data:
            optimization_params.stockout_cost_multiplier = float(data['stockout_cost_multiplier'])
        
        # Par√¢metros de servi√ßo
        if 'service_level' in data:
            optimization_params.service_level = float(data['service_level'])
            if optimization_params.service_level < 0 or optimization_params.service_level > 1:
                return jsonify({"error": "service_level deve estar entre 0 e 1"}), 400
        
        # Par√¢metros de lote
        if 'min_batch_size' in data:
            optimization_params.min_batch_size = float(data['min_batch_size'])
        if 'max_batch_size' in data:
            optimization_params.max_batch_size = float(data['max_batch_size'])
        
        # Par√¢metros operacionais
        if 'review_period_days' in data:
            optimization_params.review_period_days = int(data['review_period_days'])
        if 'consolidation_window_days' in data:
            optimization_params.consolidation_window_days = int(data['consolidation_window_days'])
        if 'daily_production_capacity' in data:
            optimization_params.daily_production_capacity = float(data['daily_production_capacity'])
        
        # Par√¢metros de habilita√ß√£o
        if 'enable_eoq_optimization' in data:
            optimization_params.enable_eoq_optimization = bool(data['enable_eoq_optimization'])
        if 'enable_consolidation' in data:
            optimization_params.enable_consolidation = bool(data['enable_consolidation'])
        
        # Novos par√¢metros avan√ßados
        if 'force_consolidation_within_leadtime' in data:
            optimization_params.force_consolidation_within_leadtime = bool(data['force_consolidation_within_leadtime'])
        if 'min_consolidation_benefit' in data:
            optimization_params.min_consolidation_benefit = float(data['min_consolidation_benefit'])
        if 'operational_efficiency_weight' in data:
            optimization_params.operational_efficiency_weight = float(data['operational_efficiency_weight'])
        if 'overlap_prevention_priority' in data:
            optimization_params.overlap_prevention_priority = bool(data['overlap_prevention_priority'])
        
        # üéØ NOVOS: Par√¢metros de auto-calculation
        if 'auto_calculate_max_batch_size' in data:
            optimization_params.auto_calculate_max_batch_size = bool(data['auto_calculate_max_batch_size'])
        if 'max_batch_multiplier' in data:
            optimization_params.max_batch_multiplier = float(data['max_batch_multiplier'])
            if optimization_params.max_batch_multiplier < 1.0 or optimization_params.max_batch_multiplier > 10.0:
                return jsonify({"error": "max_batch_multiplier deve estar entre 1.0 e 10.0"}), 400
        
        # Par√¢metro para habilitar analytics estendidos (padr√£o: True para endpoint avan√ßado)
        include_extended_analytics = data.get('include_extended_analytics', True)
        
        # Log dos par√¢metros
        logger.info("PAR√ÇMETROS AVAN√áADOS DE OTIMIZA√á√ÉO:")
        logger.info(f"  setup_cost: {optimization_params.setup_cost}")
        logger.info(f"  holding_cost_rate: {optimization_params.holding_cost_rate}")
        logger.info(f"  service_level: {optimization_params.service_level}")
        logger.info(f"  enable_eoq_optimization: {optimization_params.enable_eoq_optimization}")
        logger.info(f"  enable_consolidation: {optimization_params.enable_consolidation}")
        logger.info(f"  force_consolidation_within_leadtime: {optimization_params.force_consolidation_within_leadtime}")
        logger.info(f"  min_consolidation_benefit: {optimization_params.min_consolidation_benefit}")
        logger.info(f"  üéØ auto_calculate_max_batch_size: {optimization_params.auto_calculate_max_batch_size}")
        logger.info(f"  üéØ max_batch_multiplier: {optimization_params.max_batch_multiplier}")
        logger.info(f"  include_extended_analytics: {include_extended_analytics}")
        
        # An√°lise pr√©via das demandas
        demand_dates = list(sporadic_demand.keys())
        demand_values = list(sporadic_demand.values())
        total_demand = sum(demand_values)
        max_demand = max(demand_values)
        min_demand = min(demand_values)
        avg_demand = total_demand / len(demand_values)
        
        logger.info("AN√ÅLISE PR√âVIA DAS DEMANDAS ESPOR√ÅDICAS:")
        logger.info(f"  Total de eventos: {len(sporadic_demand)}")
        logger.info(f"  Per√≠odo das demandas: {min(demand_dates)} a {max(demand_dates)}")
        logger.info(f"  Demanda total: {total_demand}")
        logger.info(f"  Demanda m√©dia por evento: {avg_demand:.2f}")
        logger.info(f"  Demanda m√≠nima: {min_demand}")
        logger.info(f"  Demanda m√°xima: {max_demand}")
        logger.info(f"  Coeficiente de varia√ß√£o: {((max_demand - min_demand) / avg_demand):.2f}")
        
        # Detectar estrat√©gia que ser√° utilizada
        cv = (max_demand - min_demand) / avg_demand if avg_demand > 0 else 0
        if leadtime_days > 45:
            strategy_expected = "Long Lead Time Forecasting"
        elif cv > 0.5:
            strategy_expected = "Dynamic Buffer Strategy"
        elif optimization_params.enable_eoq_optimization and total_demand > optimization_params.min_batch_size * 2:
            strategy_expected = "EOQ-Based Strategy"
        else:
            strategy_expected = "Hybrid Consolidation Strategy"
        
        logger.info(f"  Estrat√©gia esperada: {strategy_expected}")
        
        # Criar otimizador MRP avan√ßado
        optimizer = MRPOptimizer(optimization_params)
        
        # Executar planejamento avan√ßado
        logger.info("Iniciando planejamento MRP AVAN√áADO...")
        result = optimizer.calculate_batches_for_sporadic_demand(
            sporadic_demand=sporadic_demand,
            initial_stock=initial_stock,
            leadtime_days=leadtime_days,
            period_start_date=period_start_date,
            period_end_date=period_end_date,
            start_cutoff_date=start_cutoff_date,
            end_cutoff_date=end_cutoff_date,
            safety_margin_percent=safety_margin_percent,
            safety_days=safety_days,
            minimum_stock_percent=minimum_stock_percent,
            max_gap_days=max_gap_days,
            include_extended_analytics=include_extended_analytics
        )
        
        # Log dos resultados b√°sicos
        analytics = result['analytics']
        summary = analytics['summary']
        
        logger.info("PLANEJAMENTO MRP AVAN√áADO CONCLU√çDO:")
        logger.info(f"Total de lotes planejados: {len(result['batches'])}")
        logger.info(f"Produ√ß√£o total: {summary['total_produced']}")
        logger.info(f"Taxa de cobertura: {summary['production_coverage_rate']}")
        logger.info(f"Taxa de atendimento: {summary['demand_fulfillment_rate']}%")
        logger.info(f"Estoque m√≠nimo: {summary['minimum_stock']}")
        logger.info(f"Estoque final: {summary['final_stock']}")
        logger.info(f"Stockout ocorreu: {summary['stockout_occurred']}")
        
        # Log de analytics estendidos (se dispon√≠veis)
        if include_extended_analytics and 'extended_analytics' in analytics:
            extended = analytics['extended_analytics']
            
            logger.info("ANALYTICS ESTENDIDOS:")
            
            # M√©tricas de performance
            if 'performance_metrics' in extended:
                perf = extended['performance_metrics']
                logger.info(f"  N√≠vel de servi√ßo realizado: {perf.get('realized_service_level', 'N/A')}%")
                logger.info(f"  Giro de estoque: {perf.get('inventory_turnover', 'N/A')}")
                logger.info(f"  Dias m√©dios de estoque: {perf.get('average_days_of_inventory', 'N/A')}")
                logger.info(f"  Frequ√™ncia de setup: {perf.get('setup_frequency', 'N/A')}")
                logger.info(f"  Tamanho m√©dio de lote: {perf.get('average_batch_size', 'N/A')}")
            
            # An√°lise de custos
            if 'cost_analysis' in extended:
                cost = extended['cost_analysis']
                logger.info(f"  Custo total estimado: R$ {cost.get('total_cost', 'N/A')}")
                logger.info(f"  Custo de setup: R$ {cost.get('setup_cost', 'N/A')}")
                logger.info(f"  Custo de manuten√ß√£o: R$ {cost.get('holding_cost', 'N/A')}")
                logger.info(f"  Custo de falta: R$ {cost.get('stockout_cost', 'N/A')}")
            
            # M√©tricas de otimiza√ß√£o
            if 'optimization_metrics' in extended:
                opt = extended['optimization_metrics']
                logger.info(f"  EOQ te√≥rico: {opt.get('theoretical_eoq', 'N/A')}")
                logger.info(f"  Lote m√©dio real: {opt.get('actual_average_batch', 'N/A')}")
                logger.info(f"  Ader√™ncia ao EOQ: {opt.get('eoq_adherence_rate', 'N/A')}%")
                logger.info(f"  Economia de consolida√ß√£o: R$ {opt.get('consolidation_savings', 'N/A')}")
            
            # An√°lise de sazonalidade
            if 'seasonality_analysis' in extended:
                season = extended['seasonality_analysis']
                logger.info(f"  Sazonalidade detectada: {season.get('seasonality_detected', 'N/A')}")
                if season.get('trend', {}).get('direction'):
                    trend = season['trend']
                    logger.info(f"  Tend√™ncia: {trend.get('direction', 'N/A')} ({trend.get('strength', 'N/A')})")
            
            # Recomenda√ß√µes
            if 'recommendations' in extended:
                recommendations = extended['recommendations']
                logger.info(f"  Recomenda√ß√µes geradas: {len(recommendations)}")
                for i, rec in enumerate(recommendations[:3], 1):  # Mostrar apenas as 3 primeiras
                    logger.info(f"    {i}. {rec.get('type', 'N/A')}: {rec.get('message', 'N/A')}")
        
        # Log detalhado dos lotes
        if result['batches']:
            logger.info(f"\nLOTES PLANEJADOS COM ALGORITMOS AVAN√áADOS:")
            for i, batch in enumerate(result['batches'], 1):
                analytics_batch = batch['analytics']
                logger.info(f"  Lote {i}:")
                logger.info(f"    Data pedido: {batch['order_date']}")
                logger.info(f"    Data chegada: {batch['arrival_date']}")
                logger.info(f"    Quantidade: {batch['quantity']}")
                logger.info(f"    Estoque antes: {analytics_batch.get('stock_before_arrival', 'N/A')}")
                logger.info(f"    Estoque depois: {analytics_batch.get('stock_after_arrival', 'N/A')}")
                logger.info(f"    Cobertura: {analytics_batch.get('coverage_days', 'N/A')} dias")
                logger.info(f"    Urg√™ncia: {analytics_batch.get('urgency_level', 'N/A')}")
                
                # Informa√ß√µes espec√≠ficas se consolidado
                if analytics_batch.get('consolidated_group', False):
                    logger.info(f"    ‚úì CONSOLIDADO: {analytics_batch.get('group_size', 'N/A')} demandas")
                    logger.info(f"    ‚úì Economia: R$ {analytics_batch.get('consolidation_savings', 'N/A')}")
                    logger.info(f"    ‚úì Qualidade: {analytics_batch.get('consolidation_quality', 'N/A')}")
                
                # Informa√ß√µes espec√≠ficas de EOQ
                if analytics_batch.get('eoq_used'):
                    logger.info(f"    ‚úì EOQ: {analytics_batch.get('eoq_used', 'N/A')}")
                
                # Informa√ß√µes espec√≠ficas de classifica√ß√£o ABC/XYZ
                if analytics_batch.get('abc_classification'):
                    logger.info(f"    ‚úì Classifica√ß√£o: {analytics_batch.get('abc_classification', 'N/A')}{analytics_batch.get('xyz_classification', '')}")
        
        # Salvar resultados completos
        with open('mrp_advanced_results.json', 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=4)
        logger.info("Resultados avan√ßados salvos em 'mrp_advanced_results.json'")
        
        logger.info("="*80)
        
        # Converter tipos numpy para tipos nativos do Python
        def convert_numpy_types(obj):
            if isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            elif hasattr(obj, 'item'):  # numpy scalar
                return obj.item()
            elif hasattr(obj, 'tolist'):  # numpy array
                return obj.tolist()
            else:
                return obj
        
        result_converted = convert_numpy_types(result)
        
        # Adicionar informa√ß√µes sobre o endpoint usado
        result_converted['_endpoint_info'] = {
            'endpoint': '/mrp_advanced',
            'version': '1.0',
            'features': [
                'Advanced MRP algorithms',
                'EOQ calculations',
                'ABC/XYZ classification',
                'Seasonality analysis',
                'Extended analytics',
                'Multiple planning strategies',
                'Intelligent consolidation',
                'Supply chain optimization'
            ],
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        return jsonify(result_converted)
        
    except Exception as ex:
        logger.error(f"Erro no planejamento MRP avan√ßado: {str(ex)}")
        logger.error(traceback.format_exc())
        return jsonify({"error": f"Falha no planejamento MRP avan√ßado: {str(ex)}"}), 500

if __name__ == "__main__":
    #logger.info("üåê CORS configurado para permitir requests de qualquer URL")
    logger.info("üì° Servidor iniciando na porta 5000...")
    app.run(debug=True, port=5000, host='127.0.0.1')
