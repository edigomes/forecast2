# Configura√ß√£o do Gunicorn para Produ√ß√£o
# Arquivo: gunicorn_config.py

import multiprocessing
import os

# Configura√ß√µes b√°sicas
bind = "0.0.0.0:5000"  # Escutar em todas as interfaces na porta 5000
workers = multiprocessing.cpu_count() * 2 + 1  # N√∫mero de workers baseado no CPU

# Configura√ß√µes de worker
worker_class = "sync"  # Tipo de worker (sync para CPU-bound, gevent para I/O-bound)
worker_connections = 1000  # Conex√µes por worker
timeout = 30  # Timeout em segundos
keepalive = 2  # Keep-alive connections

# Configura√ß√µes de processo
max_requests = 1000  # Reiniciar worker ap√≥s N requests (previne memory leaks)
max_requests_jitter = 100  # Adicionar varia√ß√£o aleat√≥ria ao max_requests
preload_app = True  # Carregar app antes de criar workers (mais eficiente)

# Configura√ß√µes de logs
accesslog = "-"  # Log de acesso no stdout
errorlog = "-"   # Log de erro no stderr
loglevel = "info"  # N√≠vel de log (debug, info, warning, error, critical)
access_log_format = '%h %l %u %t "%r" %s %b "%{Referer}i" "%{User-Agent}i" %D'

# Configura√ß√µes de seguran√ßa
limit_request_line = 4094  # Tamanho m√°ximo da linha de request
limit_request_fields = 100  # N√∫mero m√°ximo de headers
limit_request_field_size = 8190  # Tamanho m√°ximo de cada header

# Configura√ß√µes de performance
worker_tmp_dir = "/dev/shm" if os.path.exists("/dev/shm") else None  # Usar RAM para tmp (Linux)

# PID file (para gerenciamento do processo)
pidfile = "/tmp/gunicorn_forecast.pid"

# User/Group (recomendado para produ√ß√£o - execute como usu√°rio n√£o-root)
# user = "www-data"  # Descomente em produ√ß√£o Linux
# group = "www-data"  # Descomente em produ√ß√£o Linux

# Configura√ß√µes de reload (apenas para desenvolvimento)
reload = False  # N√£o usar reload em produ√ß√£o
reload_extra_files = []  # Arquivos extras para monitorar

# Print config na inicializa√ß√£o
print_config = True

# Fun√ß√£o de configura√ß√£o din√¢mica
def when_ready(server):
    """Executado quando o servidor est√° pronto"""
    print("üöÄ Servidor Forecast API est√° pronto!")
    print(f"üì° Escutando em: {bind}")
    print(f"üë• Workers: {workers}")
    print("üåê CORS habilitado para todas as origens")

def worker_int(worker):
    """Executado quando worker recebe SIGINT"""
    worker.log.info("Worker interrompido pelo usu√°rio")

def pre_fork(server, worker):
    """Executado antes de criar um worker"""
    server.log.info(f"Worker {worker.pid} est√° sendo criado")

def post_fork(server, worker):
    """Executado ap√≥s criar um worker"""
    server.log.info(f"Worker {worker.pid} criado com sucesso")

def pre_exec(server):
    """Executado antes de executar a aplica√ß√£o"""
    server.log.info("Aplica√ß√£o sendo inicializada...")

def on_exit(server):
    """Executado quando servidor √© finalizado"""
    server.log.info("üíÄ Servidor finalizado")

def on_reload(server):
    """Executado quando servidor √© recarregado"""
    server.log.info("üîÑ Servidor recarregado")

# Configura√ß√µes espec√≠ficas para ambiente
if os.getenv("ENVIRONMENT") == "production":
    # Produ√ß√£o: Mais workers, logs estruturados
    workers = multiprocessing.cpu_count() * 2 + 1
    loglevel = "warning"
    preload_app = True
    max_requests = 2000
    timeout = 60
    
elif os.getenv("ENVIRONMENT") == "staging":
    # Staging: Configura√ß√£o intermedi√°ria
    workers = 2
    loglevel = "info"
    max_requests = 1000
    timeout = 45
    
else:
    # Desenvolvimento/Local: Configura√ß√£o mais relaxada
    workers = 2
    loglevel = "debug"
    reload = True  # Permitir reload em dev
    timeout = 30 